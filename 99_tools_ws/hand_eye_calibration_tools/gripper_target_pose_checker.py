# gripper, Hand-eye Calibration rvecs, tvecs param checker SW
# 1. gripper_pose coordinate from shooting positionì—ì„œì˜ 
# 2. target coordinate from camera 

import cv2
import cv2.aruco as aruco
import numpy as np
import os
import threading
import csv

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import JointState
from moveit_msgs.srv import GetPositionFK
from moveit_msgs.msg import RobotState
from transformations import euler_from_quaternion


class FKClient(Node):
    def __init__(self):
        super().__init__('fk_client')
        self.fk_client = self.create_client(GetPositionFK, '/compute_fk')
        self.subscription = self.create_subscription(JointState, '/joint_states', self.joint_callback, 10)

        # âœ… EE pose ì €ì¥ìš© ë³€ìˆ˜ (ì´ˆê¸°ê°’)
        self.current_position = None
        self.current_orientation = None
        self.current_joint_state = None
        
        # ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°b
        while not self.fk_client.wait_for_service(timeout_sec=1.0):
            self.get_logger().info('Waiting for /compute_fk service...')

    def joint_callback(self, msg):
        # FK ì„œë¹„ìŠ¤ ìš”ì²­ ìƒì„±
        self.current_joint_state = msg
        request = GetPositionFK.Request()
        request.header.frame_id = 'world'  # ê¸°ì¤€ ì¢Œí‘œê³„
        request.fk_link_names = ['end_effector_link']    # FKë¥¼ ê³„ì‚°í•  ë§í¬ ì´ë¦„ (EE link ì´ë¦„ í™•ì¸ í•„ìš”!)
        robot_state = RobotState()
        robot_state.joint_state = msg
        request.robot_state = robot_state

        # ë¹„ë™ê¸° ì„œë¹„ìŠ¤ í˜¸ì¶œ
        future = self.fk_client.call_async(request)
        future.add_done_callback(self.fk_response_callback)

    def fk_response_callback(self, future):
        try:
            response = future.result()
            if len(response.pose_stamped) > 0:
                pose = response.pose_stamped[0].pose

                x, y, z = pose.position.x, pose.position.y, pose.position.z
                qx, qy, qz, qw = pose.orientation.x, pose.orientation.y, pose.orientation.z, pose.orientation.w
                quat = [qx, qy, qz, qw]
                roll, pitch, yaw = euler_from_quaternion(quat)

                # âœ… ì—¬ê¸°ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
                self.current_position = [x, y, z]
                self.current_orientation = [roll, pitch, yaw]

                # print(f"EE position â†’ x: {x*100:.3f}, y: {y*100:.3f}, z: {z*100:.3f}")
                # print(f"EE orientation (quaternion) â†’ x: {qx:.3f}, y: {qy:.3f}, z: {qz:.3f}, w: {qw:.3f}")
                # print(f"RPY â†’ roll: {roll:.3f}, pitch: {pitch:.3f}, yaw: {yaw:.3f}")

            else:
                print("No FK result returned.")
        except Exception as e:
            print(f"FK call failed: {e}")


class ArucoDetector:
    def __init__(self, fk_node, csv_path, camera_index=0, marker_length=0.08, calib_path=None):
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        self.cap = cv2.VideoCapture(camera_index)
        self.csv_path = csv_path
        cv2.setLogLevel(0)

        self.fk_node = fk_node  # âœ… FKClient ì¸ìŠ¤í„´ìŠ¤ ì €ì¥

        # ArUco ì„¤ì •
        self.aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)
        self.parameters = aruco.DetectorParameters()

        # ì¹´ë©”ë¼ ë³´ì • ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        if calib_path is None:
            raise ValueError("âš ï¸ Calibration file path (calib_path) must be provided.")
        data = np.load(calib_path)
        self.camera_matrix = data['mtx']
        self.dist_coeffs = data['dist']

        # ë§ˆì»¤ ê¸¸ì´
        self.marker_length = marker_length

    def detect_markers(self, frame):
        """ì…ë ¥ í”„ë ˆì„ì—ì„œ ArUco ë§ˆì»¤ íƒì§€ ë° pose ê³„ì‚°"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        corners, ids, rejected = aruco.detectMarkers(gray, self.aruco_dict, parameters=self.parameters)
        detections = []

        if ids is not None:
            rvecs, tvecs, _ = aruco.estimatePoseSingleMarkers(
                corners, self.marker_length, self.camera_matrix, self.dist_coeffs
            )
            for i in range(len(ids)):
                detection = {
                    "id": int(ids[i][0]),
                    "rvec": rvecs[i][0],
                    "tvec": tvecs[i][0],
                    "corners": corners[i][0]
                }
                detections.append(detection)
        return detections

    def draw_markers(self, frame, detections):
        """íƒì§€ëœ ë§ˆì»¤ì™€ ì¶•ì„ ì˜ìƒì— í‘œì‹œ"""
        for det in detections:
            aruco.drawDetectedMarkers(frame, [det["corners"].reshape(1, -1, 2)], np.array([[det["id"]]]))
            cv2.drawFrameAxes(frame, self.camera_matrix, self.dist_coeffs,
                              det["rvec"], det["tvec"], self.marker_length)
            cX, cY = int(det["corners"][0][0]), int(det["corners"][0][1])
            id, m_x, m_y, m_z = det['id'], det['tvec'][0], det['tvec'][1], det['tvec'][2]
            cv2.putText(frame, f"ID:{id} M X={m_x*100:.3f} Y={m_y*100:.3f} Z={m_z*100:.3f}",
                        (cX, cY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            # EE pose í…ìŠ¤íŠ¸ (ë‘ ë²ˆì§¸ ì¤„)
            if self.fk_node.current_position is not None:
                x, y, z = self.fk_node.current_position
                roll, pitch, yaw = self.fk_node.current_orientation
                cv2.putText(frame,
                    f"EE x={x*100:.3f} y={y*100:.3f} z={z*100:.3f}",
                    (cX, cY + 10),  # ğŸ‘ˆ yì¢Œí‘œë¥¼ +ë¡œ í•´ì„œ ì•„ë˜ë¡œ ì´ë™
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2
                )
        return frame

    def run(self):
        """ë©”ì¸ ë£¨í”„"""
        BASE_DIR = os.path.dirname(os.path.abspath(__file__))
        save_dir = os.path.join(BASE_DIR, 'gripper_target_pose_checker_screenshots')   # ì›í•˜ëŠ” í´ë”ëª…
        os.makedirs(save_dir, exist_ok=True)

        count = 1  # ì €ì¥ íŒŒì¼ ë²ˆí˜¸
        while True:
            ret, frame = self.cap.read()
            if not ret:
                break

            detections = self.detect_markers(frame)
            if detections:
                # for det in detections:
                #     print(f"ID {det['id']} | X={det['tvec'][0]:.3f}  Y={det['tvec'][1]:.3f}  Z={det['tvec'][2]:.3f}")
                frame = self.draw_markers(frame, detections)
            cv2.imshow("Aruco Detection", frame)
            key = cv2.waitKey(1) & 0xFF

            # âœ… ìŠ¤í˜ì´ìŠ¤ë°” â†’ í˜„ì¬ í™”ë©´ ì €ì¥
            if key == 32:  # Space
                if self.fk_node.current_position is None or self.fk_node.current_joint_state is None:
                    print("âŒ EE pose or joint state not ready, skip saving")
                    continue
                print("========== [SPACE CAPTURE] ==========")

                # EE pose ì¶œë ¥
                if self.fk_node.current_position is not None:
                    x, y, z = self.fk_node.current_position
                    roll, pitch, yaw = self.fk_node.current_orientation

                    print(f"EE pose x={x*100:.4f}, y={y*100:.4f}, z={z*100:.4f}, roll={roll:.4f}, pitch={pitch:.4f}, yaw={yaw:.4f}")
                else:
                    print("[EE pose] âŒ Not available")

                # joint ì¶œë ¥
                if self.fk_node.current_joint_state is not None:
                    js = self.fk_node.current_joint_state
                    joint_map = dict(zip(js.name, js.position))
                    ordered_joints = ["joint1", "joint2", "joint3", "joint4"]
                    pairs = [
                        f"{j}={joint_map[j]:.5f} rad"
                        for j in ordered_joints
                        if j in joint_map
                    ]
                    print(", ".join(pairs))
                else:
                    print("[Joint angles] âŒ Not available")

                # CSV ì €ì¥
                with open(self.csv_path, "a", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerow([
                        x * 100, y * 100, z * 100,
                        roll, pitch, yaw,
                        joint_map.get("joint1"),
                        joint_map.get("joint2"),
                        joint_map.get("joint3"),
                        joint_map.get("joint4"),
                    ])

                # 3ï¸âƒ£ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                filename = os.path.join(save_dir, f"EE_Marker_{count:03d}.png")
                cv2.imwrite(filename, frame)
                print(f"ğŸ“¸ Saved snapshot â†’ {filename}")
                count += 1

            if key == 27:  # ESC
                break

        self.cap.release()
        cv2.destroyAllWindows()



# ì‹¤í–‰
rclpy.init()
fk_node = FKClient()

ros_thread = threading.Thread(target=rclpy.spin, args=(fk_node,), daemon=True)
ros_thread.start()
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(BASE_DIR, "ee_joint_log.csv")
# í—¤ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
if not os.path.exists(csv_path):
    with open(csv_path, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([
            "x_cm", "y_cm", "z_cm",
            "roll_rad", "pitch_rad", "yaw_rad",
            "joint1_rad", "joint2_rad", "joint3_rad", "joint4_rad"
        ])
detector = ArucoDetector(
        fk_node=fk_node,
        csv_path=csv_path,
        camera_index=2,
        marker_length=0.08,
        calib_path = os.path.join(BASE_DIR, 'calib_data_logitech_c270.npz')

    )
detector.run()

print("ğŸ”» Shutting down...")
fk_node.destroy_node()
rclpy.shutdown()
ros_thread.join(timeout=1.0)
print("âœ… Clean exit.")